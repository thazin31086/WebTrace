{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Package Testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFUb3tt4G1dK",
        "colab_type": "code",
        "outputId": "60078053-3832-47a0-bfb3-ad4ca94fdf3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYeZz2U-TJiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "582c04ff-a030-495b-ec27-f6f01ad81d9f"
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLROES66NlcF",
        "colab_type": "code",
        "outputId": "93a14a24-3fca-43c1-fbd0-af20d5d3f98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "tokens = \"concat\"\n",
        "word_tokens = word_tokenize(tokens) \n",
        "# find those words that may be misspelled\n",
        "misspelled = spell.unknown(word_tokens)\n",
        "print(misspelled)\n",
        "for word in misspelled:\n",
        "    # Get the one `most likely` answer\n",
        "    print(spell.correction(word))\n",
        "\n",
        "    # Get a list of `likely` options\n",
        "    print(spell.candidates(word))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'concat'}\n",
            "conca\n",
            "{'conca'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CShwSJMWZMLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction import stop_words\n",
        " \n",
        "print(stop_words.ENGLISH_STOP_WORDS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq3OdsJYYom6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caJv95OCnhoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('punkt')\n",
        "\n",
        "set(stopwords.words('english'))\n",
        "\n",
        "text = \"visual studio 2019 crashing when click rmb on rule in analyzers' dependencies\"\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "  \n",
        "print(text)\n",
        "word_tokens = word_tokenize(text) \n",
        "print(word_tokens)    \n",
        "filtered_sentence = [] \n",
        "  \n",
        "for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        filtered_sentence.append(w) \n",
        "print(' '.join(filtered_sentence))\n",
        "\n",
        "lemma_word = []\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "for w in filtered_sentence:\n",
        "    word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
        "    word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "    word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "    lemma_word.append(word3)\n",
        "print(' '.join(lemma_word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM1Y4I8O0Htk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install wikipedia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcnJ6FNw0QAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9c5545df-e9f1-49e2-a993-1a5e012d12ba"
      },
      "source": [
        "import wikipedia\n",
        "import re\n",
        "\n",
        "\n",
        "\"Visual Studio 2019 crashing when click RMB on rule in Analyzers' dependencies\",#https://github.com/dotnet/roslyn/issues/40720\n",
        "\"Crash on right click a Analyze rule in Solution-Explorer\", #https://github.com/dotnet/roslyn/issues/36304\n",
        "\"Handle lazy loading of analyzer command handlers\", #https://github.com/dotnet/roslyn/pull/36740\n",
        "\n",
        "result = wikipedia.search(\"OS\")[0]\n",
        "result = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", result)\n",
        "print(result)\n",
        "\n",
        "wiki_list = wikipedia.search(\"Analyzers\")\n",
        "\n",
        "print(wiki_list)\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OS\n",
            "['Spectrum analyzer', 'Network analyzer (electrical)', 'Logic analyzer', 'Packet analyzer', 'Hematology analyzer', 'Network analyzer (AC power)', 'Mass spectrometry', 'Coal analyzer', 'Impedance analyzer', 'Audio analyzer']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfYDxSQpS54B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5eb43d7d-7f61-4b48-ad7c-cee97662e84d"
      },
      "source": [
        ""
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (45.1.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144675 sha256=39c22f79f104221f435d8aedb070a6aa9e0cc55eeeff900ba8a52fefd83ca2d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}