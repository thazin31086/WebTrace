{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-Mean Ebowl Curve.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS3rGxlrMCry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a3054f8c-6d8e-418b-dcbd-6ea33280b84e"
      },
      "source": [
        "#https://www.kaggle.com/dipikabaad0107/elbow-curve-for-text-clustering/code\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "#import csv\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "#from stop_words import get_stop_words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "en_stop = set(stopwords.words('english'))\n",
        "# Create p_stemmer of class PorterStemmer\n",
        "#p_stemmer = PorterStemmer()\n",
        "\n",
        "df9 = pd.read_csv(\"efcore.csv\")\n",
        "\n",
        "texts = []\n",
        "################################### Remove numbers and single letter words\n",
        "# loop through document list\n",
        "for i in df9['Title']:\n",
        "    \n",
        "    # clean and tokenize document string\n",
        "    raw = i.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "\n",
        "    # remove stop words from tokens\n",
        "    stopped_tokens = [i for i in tokens if (not i in en_stop and not str(i).isdigit() and len(str(i)) > 2 )]\n",
        "    \n",
        "    # stem tokens\n",
        "    #stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
        "    \n",
        "    # add tokens to list\n",
        "    texts.append(stopped_tokens)\n",
        "    \n",
        "df9['Cleaned_PaperText'] = pd.Series(texts, index = df9.index)\n",
        "        \n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df9.Title)\n",
        "km = KMeans(n_clusters=10, init='k-means++', max_iter=100)\n",
        "km.fit(X)\n",
        "km.labels_\n",
        "\n",
        "# k means determine k\n",
        "distortions = []\n",
        "K = range(1,100)\n",
        "for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k).fit(X)\n",
        "    kmeanModel.fit(X)\n",
        "    #distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
        " \n",
        "### One more method for \n",
        "\n",
        "for n_cluster in range(2, 10):\n",
        "    kmeans = KMeans(n_clusters=n_cluster).fit(X)\n",
        "    label = kmeans.labels_\n",
        "    sil_coeff = silhouette_score(X, label, metric='euclidean')\n",
        "    print(\"For n_clusters={}, The Silhouette Coefficient is {}\".format(n_cluster, sil_coeff))\n",
        "##dictionary = corpora.Dictionary(texts)\n",
        "#corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "#df9['Corpus'] = pd.Series(corpus, index = df9.index)\n",
        "\n",
        "##### Inertia error method\n",
        "cluster_range = range( 1, 10 )\n",
        "cluster_errors = []\n",
        "for num_clusters in cluster_range:\n",
        "   clusters = KMeans( num_clusters )\n",
        "   clusters.fit( X )\n",
        "   cluster_errors.append( clusters.inertia_ )\n",
        "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}